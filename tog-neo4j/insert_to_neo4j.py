"""
Neo4j å¯¼å…¥å·¥å…·
æ”¯æŒå¤šçŸ¥è¯†åº“éš”ç¦»å­˜å‚¨ï¼Œé€šè¿‡ grag_id åŒºåˆ†
"""

import json
import os
from neo4j import GraphDatabase
from typing import List, Dict, Any


class Neo4jImporter:
    """Neo4j æ•°æ®å¯¼å…¥å™¨ï¼Œæ”¯æŒçŸ¥è¯†åº“éš”ç¦»"""

    def __init__(self, uri: str, user: str, password: str):
        """
        åˆå§‹åŒ– Neo4j è¿æ¥

        Args:
            uri: Neo4j è¿æ¥åœ°å€
            user: ç”¨æˆ·å
            password: å¯†ç 
        """
        self.uri = uri
        self.user = user
        self.driver = GraphDatabase.driver(uri, auth=(user, password))
        print(f"[INFO] å·²è¿æ¥åˆ° Neo4j: {uri}")

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.driver:
            self.driver.close()
            print("[INFO] Neo4j è¿æ¥å·²å…³é—­")

    def load_json_data(self, json_file: str) -> Dict[str, Any]:
        """åŠ è½½ JSON æ•°æ®æ–‡ä»¶"""
        if not os.path.exists(json_file):
            raise FileNotFoundError(f"æ–‡ä»¶æœªæ‰¾åˆ°: {json_file}")

        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        print(f"[INFO] åŠ è½½æ•°æ®æ–‡ä»¶: {json_file}")
        print(f"[INFO] çŸ¥è¯†åº“ID: {data['metadata']['grag_id']}")
        print(f"[INFO] å®ä½“æ•°: {data['metadata']['entity_count']}")
        print(f"[INFO] å…³ç³»æ•°: {data['metadata']['triple_count']}")

        return data

    def clear_database(self):
        """æ¸…ç©ºæ•´ä¸ªæ•°æ®åº“ï¼ˆæ…ç”¨ï¼ï¼‰"""
        with self.driver.session() as session:
            session.run("MATCH (n) DETACH DELETE n")
        print("[WARNING] æ•°æ®åº“å·²æ¸…ç©º")

    def clear_knowledge_base(self, grag_id: str):
        """
        åˆ é™¤æŒ‡å®šçŸ¥è¯†åº“çš„æ‰€æœ‰æ•°æ®ï¼ˆä½¿ç”¨ DETACH DELETE å¼ºåˆ¶åˆ é™¤èŠ‚ç‚¹åŠå…¶æ‰€æœ‰å…³ç³»ï¼‰
        """
        with self.driver.session() as session:
            # ğŸ”´ ä½¿ç”¨ DETACH DELETEï¼šåŒæ—¶åˆ é™¤èŠ‚ç‚¹å’Œå®ƒè¿æ¥çš„æ‰€æœ‰å…³ç³»
            result = session.run("""
                MATCH (n:Entity {grag_id: $grag_id})
                DETACH DELETE n
                RETURN count(n) as deleted_nodes
            """, grag_id=grag_id)

            deleted_nodes = result.single()['deleted_nodes']

        print(f"[INFO] å·²åˆ é™¤çŸ¥è¯†åº“ '{grag_id}': {deleted_nodes} ä¸ªèŠ‚ç‚¹åŠå…¶æ‰€æœ‰å…³è”å…³ç³»")

    def create_constraints_and_indexes(self):
        """
        åˆ›å»ºçº¦æŸå’Œç´¢å¼•
        å…³é”®ï¼šä½¿ç”¨ (id, grag_id) å¤åˆçº¦æŸï¼Œç¡®ä¿ä¸åŒçŸ¥è¯†åº“çš„ç›¸åŒå®ä½“ç‹¬ç«‹å­˜å‚¨
        """
        with self.driver.session() as session:
            try:
                # åˆ é™¤æ—§çš„å•å­—æ®µçº¦æŸï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                try:
                    session.run("DROP CONSTRAINT entity_id IF EXISTS")
                except:
                    pass

                # ğŸ”´ æ ¸å¿ƒï¼šåˆ›å»ºå¤åˆå”¯ä¸€çº¦æŸ
                # ç›¸åŒ id ä½†ä¸åŒ grag_id çš„å®ä½“ä¼šè¢«è§†ä¸ºä¸åŒèŠ‚ç‚¹
                session.run("""
                    CREATE CONSTRAINT entity_composite_key IF NOT EXISTS 
                    FOR (e:Entity) REQUIRE (e.id, e.grag_id) IS UNIQUE
                """)
                print("[INFO] âœ“ åˆ›å»ºå¤åˆå”¯ä¸€çº¦æŸ (id, grag_id)")

                # åˆ›å»ºç´¢å¼•ä»¥åŠ é€ŸæŸ¥è¯¢
                session.run("CREATE INDEX entity_name IF NOT EXISTS FOR (e:Entity) ON (e.name)")
                # print("[INFO] âœ“ åˆ›å»ºç´¢å¼•: entity_name")

                session.run("CREATE INDEX entity_type IF NOT EXISTS FOR (e:Entity) ON (e.type)")
                # print("[INFO] âœ“ åˆ›å»ºç´¢å¼•: entity_type")

                session.run("CREATE INDEX entity_grag_id IF NOT EXISTS FOR (e:Entity) ON (e.grag_id)")
                # print("[INFO] âœ“ åˆ›å»ºç´¢å¼•: entity_grag_id")

            except Exception as e:
                print(f"[WARNING] åˆ›å»ºçº¦æŸ/ç´¢å¼•æ—¶å‡ºç°é—®é¢˜: {e}")

    def import_entities(self, entities: Dict[str, Dict[str, Any]]):
        """
        å¯¼å…¥å®ä½“æ•°æ®
        ä½¿ç”¨ (id, grag_id) è”åˆåŒ¹é…ï¼Œç¡®ä¿çŸ¥è¯†åº“éš”ç¦»
        """
        entities_list = []
        for entity_id, entity_data in entities.items():
            entity_data['id'] = entity_id
            entities_list.append(entity_data)

        with self.driver.session() as session:
            # ğŸ”´ æ ¸å¿ƒï¼šMERGE åŸºäº (id, grag_id) è”åˆä¸»é”®
            session.run("""
                UNWIND $entities AS entity
                MERGE (e:Entity {id: entity.id, grag_id: entity.grag_id})
                SET e.name = entity.name,
                    e.type = entity.type,
                    e.description = entity.description,
                    e.degree = entity.degree,
                    e.community_ids = entity.community_ids,
                    e.text_unit_ids = entity.text_unit_ids
            """, entities=entities_list)

        print(f"[INFO] âœ“ å¯¼å…¥ {len(entities_list)} ä¸ªå®ä½“")

    def import_relationships_without_apoc(self, triples: List[Dict[str, Any]]):
        """
        å¯¼å…¥å…³ç³»æ•°æ®
        å…³ç³»åŒ¹é…æ—¶åŒæ—¶è€ƒè™‘ grag_idï¼Œç¡®ä¿åªåœ¨åŒä¸€çŸ¥è¯†åº“å†…å»ºç«‹è¿æ¥
        """
        if not triples:
            print("[INFO] æ— å…³ç³»éœ€è¦å¯¼å…¥")
            return

        # è‡ªåŠ¨è¯†åˆ«ä¸»é”®å­—æ®µ
        sample = triples[0]
        subject_key = next((k for k in ['subject_id', 'subject', 'source', 'head'] if k in sample), None)
        object_key = next((k for k in ['object_id', 'object', 'target', 'tail'] if k in sample), None)

        if not subject_key or not object_key:
            print("[ERROR] æ— æ³•è¯†åˆ«ä¸»ä½“å’Œå®¢ä½“å­—æ®µ")
            return

        # åˆ¤æ–­ä½¿ç”¨ id è¿˜æ˜¯ name åŒ¹é…
        sample_id_val = str(sample[subject_key])
        is_uuid_like = ('-' in sample_id_val and len(sample_id_val) > 20) or len(sample_id_val) == 32
        match_field = "id" if is_uuid_like else "name"

        print(f"[INFO] ä½¿ç”¨å­—æ®µ '{match_field}' åŒ¹é…å®ä½“")

        # æŒ‰å…³ç³»ç±»å‹åˆ†ç»„
        relations_by_type = {}
        for triple in triples:
            original_predicate = triple.get('predicate', 'RELATED_TO')
            rel_type = self._normalize_relationship_type(original_predicate)

            if rel_type not in relations_by_type:
                relations_by_type[rel_type] = []

            relations_by_type[rel_type].append({
                'subject_val': triple[subject_key],
                'object_val': triple[object_key],
                'weight': triple.get('weight', 0.0),
                'description': triple.get('description', ''),
                'original_predicate': original_predicate,
                'grag_id': triple.get('grag_id', '')  # ğŸ”´ å…³é”®ï¼šä¼ é€’ grag_id
            })

        # æ‰¹é‡å¯¼å…¥å…³ç³»
        with self.driver.session() as session:
            for rel_type, rel_triples in relations_by_type.items():
                # ğŸ”´ æ ¸å¿ƒï¼šMATCH æ—¶åŒæ—¶åŒ¹é… grag_idï¼Œç¡®ä¿åªè¿æ¥åŒä¸€çŸ¥è¯†åº“çš„èŠ‚ç‚¹
                query = f"""
                    UNWIND $triples AS triple
                    MATCH (source:Entity) 
                    WHERE source.{match_field} = triple.subject_val 
                      AND source.grag_id = triple.grag_id
                    MATCH (target:Entity) 
                    WHERE target.{match_field} = triple.object_val 
                      AND target.grag_id = triple.grag_id
                    MERGE (source)-[r:{rel_type}]->(target)
                    SET r.weight = triple.weight, 
                        r.description = triple.description, 
                        r.original_predicate = triple.original_predicate,
                        r.grag_id = triple.grag_id
                """
                session.run(query, triples=rel_triples)
                # print(f"[INFO] âœ“ å¯¼å…¥å…³ç³»ç±»å‹ '{rel_type}': {len(rel_triples)} æ¡")

    def _normalize_relationship_type(self, predicate: str) -> str:
        """æ ‡å‡†åŒ–å…³ç³»ç±»å‹åç§°"""
        if not predicate or not predicate.strip():
            return 'RELATED_TO'

        normalized = predicate.strip().replace(' ', '_')
        normalized = ''.join(c if c.isalnum() or c == '_' else '_' for c in normalized).upper()

        while '__' in normalized:
            normalized = normalized.replace('__', '_')

        normalized = normalized.strip('_')

        if not normalized or normalized.replace('_', '') == '':
            return 'RELATED_TO'

        if normalized[0].isdigit():
            normalized = 'REL_' + normalized

        return normalized

    def get_knowledge_base_stats(self, grag_id: str) -> Dict[str, int]:
        """
        è·å–æŒ‡å®šçŸ¥è¯†åº“çš„ç»Ÿè®¡ä¿¡æ¯

        Args:
            grag_id: çŸ¥è¯†åº“ID

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        with self.driver.session() as session:
            # ç»Ÿè®¡èŠ‚ç‚¹æ•°
            result = session.run("""
                MATCH (n:Entity {grag_id: $grag_id})
                RETURN count(n) as node_count
            """, grag_id=grag_id)
            node_count = result.single()['node_count']

            # ç»Ÿè®¡å…³ç³»æ•°
            result = session.run("""
                MATCH ()-[r {grag_id: $grag_id}]-()
                RETURN count(r) as rel_count
            """, grag_id=grag_id)
            rel_count = result.single()['rel_count']

        return {
            'grag_id': grag_id,
            'node_count': node_count,
            'relationship_count': rel_count
        }


def main(json_file: str,
         neo4j_uri: str = "bolt://localhost:7687",
         neo4j_user: str = "neo4j",
         neo4j_password: str = "jbh966225",
         clear_existing: bool = False) -> bool:
    """
    ä¸»å‡½æ•°ï¼šå¯¼å…¥æ•°æ®åˆ° Neo4j

    Args:
        json_file: ç”± deal_graph.py ç”Ÿæˆçš„ JSON æ–‡ä»¶è·¯å¾„
        neo4j_uri: Neo4j è¿æ¥åœ°å€
        neo4j_user: Neo4j ç”¨æˆ·å
        neo4j_password: Neo4j å¯†ç 
        clear_existing: æ˜¯å¦æ¸…é™¤å·²å­˜åœ¨çš„åŒåçŸ¥è¯†åº“

    Returns:
        bool: æˆåŠŸè¿”å› Trueï¼Œå¤±è´¥è¿”å› False
    """
    importer = None
    try:
        # è¿æ¥æ•°æ®åº“
        importer = Neo4jImporter(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)

        # åŠ è½½æ•°æ®
        data = importer.load_json_data(json_file)
        grag_id = data['metadata']['grag_id']

        # å¦‚æœéœ€è¦ï¼Œæ¸…é™¤å·²å­˜åœ¨çš„çŸ¥è¯†åº“
        if clear_existing:
            importer.clear_knowledge_base(grag_id)

        # åˆ›å»ºçº¦æŸå’Œç´¢å¼•
        importer.create_constraints_and_indexes()

        # å¯¼å…¥å®ä½“
        importer.import_entities(data['entities'])

        # å¯¼å…¥å…³ç³»
        importer.import_relationships_without_apoc(data['triples'])

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = importer.get_knowledge_base_stats(grag_id)
        print(f"\n{'='*60}")
        print(f"âœ… çŸ¥è¯†åº“ '{grag_id}' å¯¼å…¥æˆåŠŸï¼")
        print(f"{'='*60}")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   - èŠ‚ç‚¹æ•°: {stats['node_count']}")
        print(f"   - å…³ç³»æ•°: {stats['relationship_count']}")
        print(f"{'='*60}\n")

        return True

    except FileNotFoundError as e:
        print(f"[ERROR] æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        return False
    except Exception as e:
        print(f"[ERROR] å¯¼å…¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        if importer:
            importer.close()


if __name__ == "__main__":
    from insert_to_neo4j import Neo4jImporter
    # å®šä¹‰ä¸€ä¸ªä¿®å¤åçš„åˆ é™¤æ–¹æ³•
    def safe_clear_knowledge_base(importer, grag_id):
        print(f"æ­£åœ¨å¼ºåˆ¶æ¸…ç†çŸ¥è¯†åº“: {grag_id} ...")
        with importer.driver.session() as session:
            # DETACH DELETE ä¼šè‡ªåŠ¨å¤„ç†æ®‹ç•™çš„å…³ç³»
            result = session.run("""
                MATCH (n:Entity {grag_id: $grag_id})
                DETACH DELETE n
                RETURN count(n) as deleted_count
            """, grag_id=grag_id)
            count = result.single()['deleted_count']
        print(f"âœ… æˆåŠŸåˆ é™¤ {count} ä¸ªèŠ‚ç‚¹åŠå…¶æ‰€æœ‰å…³ç³»ã€‚")


    # --- æ‰§è¡Œéƒ¨åˆ† ---
    neo4j_uri = "bolt://localhost:7687"
    neo4j_user = "neo4j"
    neo4j_password = "jbh966225"
    target_grag_id = "2026001_1"

    importer = Neo4jImporter(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)

    try:
        safe_clear_knowledge_base(importer, target_grag_id)
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        importer.close()
    # # æµ‹è¯•è°ƒç”¨
    # test_file = "./output/extracted_data/graph_data.json"
    #
    # success = main(
    #     json_file=test_file,
    #     neo4j_uri="bolt://localhost:7687",
    #     neo4j_user="neo4j",
    #     neo4j_password="jbh966225",
    #     clear_existing=False  # è®¾ä¸º True ä¼šå…ˆåˆ é™¤åŒåçŸ¥è¯†åº“
    # )
    #
    # if success:
    #     print("âœ… æµç¨‹ç»“æŸï¼šå¯¼å…¥æˆåŠŸ")
    # else:
    #     print("âŒ æµç¨‹ç»“æŸï¼šå¯¼å…¥å¤±è´¥")