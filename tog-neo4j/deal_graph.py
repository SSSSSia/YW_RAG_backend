"""
GraphRAG ä¸‰å…ƒç»„æå–å·¥å…·
æ¯ä¸ª output æ–‡ä»¶å¤¹ä½œä¸ºç‹¬ç«‹çŸ¥è¯†åº“ï¼Œé€šè¿‡ grag_id æ ‡è¯†
"""

import pandas as pd
import json
import os
from typing import List, Dict, Any
from datetime import datetime


class GraphRAGExtractor:
    """ä» GraphRAG è¾“å‡ºä¸­æå–ä¸‰å…ƒç»„å¹¶æ ‡è®° grag_id"""

    def __init__(self, input_dir: str, output_dir: str = None, grag_id: str = ""):
        """
        åˆå§‹åŒ–æå–å™¨

        Args:
            input_dir: GraphRAG çš„ output æ–‡ä»¶å¤¹è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸º input_dir/extracted_data
            grag_id: çŸ¥è¯†åº“å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œå¿…é¡»æä¾›
        """
        if not grag_id or not grag_id.strip():
            raise ValueError("grag_id ä¸èƒ½ä¸ºç©ºï¼æ¯ä¸ªçŸ¥è¯†åº“å¿…é¡»æœ‰å”¯ä¸€æ ‡è¯†")

        self.input_dir = input_dir
        self.grag_id = grag_id.strip()

        # é»˜è®¤è¾“å‡ºåˆ° input_dir ä¸‹çš„ extracted_data ç›®å½•
        if output_dir is None:
            self.output_dir = os.path.join(input_dir, "extracted_data")
        else:
            self.output_dir = output_dir

        os.makedirs(self.output_dir, exist_ok=True)

    def load_entities(self) -> pd.DataFrame:
        """åŠ è½½å®ä½“æ•°æ®"""
        file_path = os.path.join(self.input_dir, "entities.parquet")
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°å®ä½“æ–‡ä»¶: {file_path}")
        return pd.read_parquet(file_path)

    def load_relationships(self) -> pd.DataFrame:
        """åŠ è½½å…³ç³»æ•°æ®"""
        file_path = os.path.join(self.input_dir, "relationships.parquet")
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°å…³ç³»æ–‡ä»¶: {file_path}")
        return pd.read_parquet(file_path)

    def extract_entities(self, entities_df: pd.DataFrame) -> Dict[str, Dict[str, Any]]:
        """
        æå–å®ä½“ä¿¡æ¯ï¼Œæ¯ä¸ªå®ä½“éƒ½æ ‡è®° grag_id

        Returns:
            å®ä½“å­—å…¸ï¼Œkey ä¸º entity_id
        """
        entity_dict = {}
        for _, row in entities_df.iterrows():
            entity_id = str(row.get('id', row.get('human_readable_id', '')))
            entity_dict[entity_id] = {
                'id': entity_id,
                'name': str(row.get('name', row.get('title', ''))),
                'type': str(row.get('type', 'ENTITY')),
                'description': str(row.get('description', '')),
                'degree': int(row.get('degree', 0)) if pd.notna(row.get('degree')) else 0,
                'community_ids': self._safe_list(row.get('community_ids', [])),
                'text_unit_ids': self._safe_list(row.get('text_unit_ids', [])),
                'grag_id': self.grag_id  # ğŸ”´ å…³é”®ï¼šæ ‡è®°çŸ¥è¯†åº“ID
            }
        return entity_dict

    def extract_triples(self,
                        relationships_df: pd.DataFrame,
                        entity_dict: Dict[str, Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        æå–ä¸‰å…ƒç»„ä¿¡æ¯ï¼Œæ¯æ¡å…³ç³»éƒ½æ ‡è®° grag_id

        Returns:
            ä¸‰å…ƒç»„åˆ—è¡¨
        """
        triples = []
        for idx, row in relationships_df.iterrows():
            source_id = str(row.get('source', ''))
            target_id = str(row.get('target', ''))

            # è·å–å®ä½“åç§°
            source_name = entity_dict.get(source_id, {}).get('name', source_id)
            target_name = entity_dict.get(target_id, {}).get('name', target_id)

            triple = {
                'id': f"rel_{idx}",
                'subject': source_name,
                'subject_id': source_id,
                'predicate': str(row.get('type', row.get('description', 'RELATED_TO'))),
                'object': target_name,
                'object_id': target_id,
                'weight': float(row.get('weight', 1.0)) if pd.notna(row.get('weight')) else 1.0,
                'description': str(row.get('description', '')),
                'source_degree': int(row.get('source_degree', 0)) if pd.notna(row.get('source_degree')) else 0,
                'target_degree': int(row.get('target_degree', 0)) if pd.notna(row.get('target_degree')) else 0,
                'rank': int(row.get('rank', 0)) if pd.notna(row.get('rank')) else 0,
                'grag_id': self.grag_id  # ğŸ”´ å…³é”®ï¼šæ ‡è®°çŸ¥è¯†åº“ID
            }
            triples.append(triple)
        return triples

    def _safe_list(self, value):
        """å®‰å…¨è½¬æ¢ä¸ºåˆ—è¡¨"""
        import numpy as np
        if value is None:
            return []
        if isinstance(value, np.ndarray):
            return value.tolist() if value.size > 0 else []
        if pd.isna(value) and not hasattr(value, '__len__'):
            return []
        if isinstance(value, (list, tuple, set)):
            return list(value)
        if isinstance(value, str):
            return [value]
        return []

    def run(self) -> str:
        """
        æ‰§è¡Œæå–æµç¨‹

        Returns:
            ç”Ÿæˆçš„ JSON æ–‡ä»¶è·¯å¾„
        """
        print(f"[INFO] å¼€å§‹æå–çŸ¥è¯†åº“: {self.grag_id}")
        print(f"[INFO] è¾“å…¥ç›®å½•: {self.input_dir}")

        # åŠ è½½æ•°æ®
        entities_df = self.load_entities()
        relationships_df = self.load_relationships()
        print(f"[INFO] åŠ è½½ {len(entities_df)} ä¸ªå®ä½“, {len(relationships_df)} æ¡å…³ç³»")

        # æå–æ•°æ®
        entities = self.extract_entities(entities_df)
        triples = self.extract_triples(relationships_df, entities)

        # æ„å»ºè¾“å‡ºæ•°æ®
        output_path = os.path.join(self.output_dir, "graph_data.json")
        data = {
            'metadata': {
                'extraction_time': datetime.now().isoformat(),
                'source_directory': self.input_dir,
                'grag_id': self.grag_id,
                'entity_count': len(entities),
                'triple_count': len(triples)
            },
            'entities': entities,
            'triples': triples
        }

        # ä¿å­˜ JSON æ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"[SUCCESS] æ•°æ®å·²æå–è‡³: {output_path}")
        return output_path


def main(input_dir: str, grag_id: str) -> str | None:
    """
    ä¸»å‡½æ•°ï¼šæå–æ•°æ®å¹¶è¿”å›æ–‡ä»¶è·¯å¾„

    Args:
        input_dir: GraphRAG çš„ output æ–‡ä»¶å¤¹è·¯å¾„
        grag_id: çŸ¥è¯†åº“å”¯ä¸€æ ‡è¯†ç¬¦

    Returns:
        str: æˆåŠŸæ—¶è¿”å›ç”Ÿæˆçš„ JSON æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
        None: å¤±è´¥æ—¶è¿”å› None
    """
    try:
        if not grag_id or not grag_id.strip():
            print("[ERROR] grag_id ä¸èƒ½ä¸ºç©º")
            return None

        extractor = GraphRAGExtractor(input_dir=input_dir, grag_id=grag_id)
        output_path = extractor.run()
        return os.path.abspath(output_path)

    except FileNotFoundError as e:
        print(f"[ERROR] æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        return None
    except Exception as e:
        print(f"[ERROR] æå–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    # æµ‹è¯•è°ƒç”¨
    result_path = main(
        input_dir="./output",
        grag_id="knowledge_base_20250112_001"
    )

    if result_path:
        print(f"\nâœ… ç”Ÿæˆæ–‡ä»¶: {result_path}")
    else:
        print("\nâŒ æå–å¤±è´¥")