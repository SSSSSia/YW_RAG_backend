"""
è‡ªåŠ¨æŸ¥è¯¢ Agent - æ ¹æ®é—®é¢˜è‡ªåŠ¨é€‰æ‹©æœ€ä½³æŸ¥è¯¢æ–¹æ³•
æ”¯æŒæŒ‡å®šçŸ¥è¯†åº“ä¼˜å…ˆæŸ¥è¯¢ï¼Œå¤±è´¥åè‡ªåŠ¨å›é€€åˆ°å…¶ä»–çŸ¥è¯†åº“
"""
import time
from agents.base import BaseAgent, AgentContext, AgentResult
from agents.tools import QueryToGTool, QueryGraphRAGTool, QueryHybridTool
from core.llm_client import llm_client
from utils.logger import logger


class AutoQueryAgent(BaseAgent):
    """è‡ªåŠ¨æŸ¥è¯¢ Agent"""

    def __init__(self):
        super().__init__(
            name="AutoQueryAgent",
            description="ä¸“é—¨å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼Œæ ¹æ®é—®é¢˜å¤æ‚åº¦è‡ªåŠ¨é€‰æ‹©æœ€ä½³æŸ¥è¯¢æ–¹æ³•ï¼Œæ”¯æŒè·¨çŸ¥è¯†åº“å›é€€æŸ¥è¯¢"
        )
        # æ³¨å†Œå·¥å…·
        self.tog_tool = QueryToGTool()
        self.graphrag_tool = QueryGraphRAGTool()
        self.hybrid_tool = QueryHybridTool()

        self.register_tool(self.tog_tool)
        self.register_tool(self.graphrag_tool)
        self.register_tool(self.hybrid_tool)

    def can_handle(self, context: AgentContext) -> bool:
        """åˆ¤æ–­æ˜¯å¦èƒ½å¤„ç†è¯¥ä»»åŠ¡"""
        query_keywords = ['æŸ¥è¯¢', 'æœç´¢', 'æŸ¥æ‰¾', 'å‘Šè¯‰æˆ‘', 'ä»€ä¹ˆæ˜¯', 'è°æ˜¯', 'å¦‚ä½•', 'ä¸ºä»€ä¹ˆ', 'query', 'search']
        return any(kw in context.question.lower() for kw in query_keywords)

    async def execute(self, context: AgentContext) -> AgentResult:
        """
        æ‰§è¡Œè‡ªåŠ¨æŸ¥è¯¢ï¼ˆå«å›é€€é€»è¾‘ï¼‰
        é€»è¾‘ï¼š
        1. å¦‚æœç”¨æˆ·æŒ‡å®šäº† grag_idï¼Œä¼˜å…ˆå°è¯•æŸ¥è¯¢è¯¥çŸ¥è¯†åº“ã€‚
        2. å¦‚æœæŒ‡å®šçŸ¥è¯†åº“æŸ¥è¯¢æˆåŠŸä¸”ç­”æ¡ˆæœ‰æ•ˆï¼Œç›´æ¥è¿”å›ã€‚
        3. å¦‚æœå¤±è´¥æˆ–æ— æœ‰æ•ˆç­”æ¡ˆï¼Œå°è¯•æŸ¥è¯¢å…¶ä»–å¯ç”¨çŸ¥è¯†åº“ã€‚
        """
        start_time = time.time()
        user_specific_id = context.grag_id
        all_kbs = context.metadata.get("all_kbs", [])

        logger.info(f"[{context.grag_id}] ğŸ¤– AutoQueryAgent å¼€å§‹æ‰§è¡Œ")
        logger.info(f"[{context.grag_id}] ğŸ¯ ç”¨æˆ·æŒ‡å®šID: {user_specific_id}, å¯ç”¨çŸ¥è¯†åº“æ•°: {len(all_kbs)}")

        # ============================================================
        # æ­¥éª¤ 1: ä¼˜å…ˆæŸ¥è¯¢ç”¨æˆ·æŒ‡å®šçš„çŸ¥è¯†åº“
        # ============================================================
        if user_specific_id and user_specific_id != "default":
            logger.info(f"[{user_specific_id}] ğŸ” æ­¥éª¤1: å°è¯•æŸ¥è¯¢ç”¨æˆ·æŒ‡å®šçš„çŸ¥è¯†åº“")

            # åˆ›å»ºä¸´æ—¶ä¸Šä¸‹æ–‡ï¼Œä»…åŒ…å«å½“å‰æŒ‡å®šçš„çŸ¥è¯†åº“ID
            temp_context = AgentContext(
                grag_id=user_specific_id,
                question=context.question,
                conversation_history=context.conversation_history,
                metadata=context.metadata.copy()
            )

            # æ‰§è¡ŒæŸ¥è¯¢
            result = await self._execute_query_logic(temp_context)

            # æ£€æŸ¥ç»“æœæœ‰æ•ˆæ€§
            if result.get("success"):
                answer = result.get("answer") or result.get("final_answer", "")
                # ç®€å•åˆ¤æ–­ç­”æ¡ˆæœ‰æ•ˆæ€§ï¼šé•¿åº¦å¤§äº20å­—ç¬¦
                if answer and len(answer) > 20:
                    execution_time = time.time() - start_time
                    logger.info(f"[{user_specific_id}] âœ… æŒ‡å®šçŸ¥è¯†åº“æŸ¥è¯¢æˆåŠŸï¼Œç›´æ¥è¿”å›")
                    return AgentResult(
                        success=True,
                        data={
                            "question": context.question,
                            "answer": answer,
                            "method_used": result.get("method", "unknown"),
                            "grag_id": user_specific_id
                        },
                        message=f"åœ¨æŒ‡å®šçŸ¥è¯†åº“ä¸­æŸ¥è¯¢æˆåŠŸ",
                        execution_time=execution_time,
                        metadata={"method": result.get("method"), "kb_name": "ç”¨æˆ·æŒ‡å®šçŸ¥è¯†åº“"}
                    )

            # å¦‚æœæŒ‡å®šçŸ¥è¯†åº“æ²¡æŸ¥åˆ°æœ‰æ•ˆç»“æœï¼Œè®°å½•æ—¥å¿—å¹¶å‡†å¤‡å›é€€
            logger.warning(f"[{user_specific_id}] âš ï¸ æŒ‡å®šçŸ¥è¯†åº“æŸ¥è¯¢æ— æœ‰æ•ˆç»“æœï¼Œå¼€å§‹å›é€€æŸ¥è¯¢å…¶ä»–çŸ¥è¯†åº“...")

        # ============================================================
        # æ­¥éª¤ 2: å›é€€é€»è¾‘ - æŸ¥è¯¢å…¶ä»–çŸ¥è¯†åº“
        # ============================================================

        # è¿‡æ»¤æ‰å·²ç»æŸ¥è¯¢è¿‡çš„é‚£ä¸ªï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        fallback_kbs = [kb for kb in all_kbs if kb.get("grag_id") != user_specific_id]

        if not fallback_kbs:
            logger.info(f"[{context.grag_id}] ğŸ“­ æ²¡æœ‰å…¶ä»–å¯å›é€€çš„çŸ¥è¯†åº“")
            return AgentResult(
                success=False,
                data=None,
                message="æŒ‡å®šçŸ¥è¯†åº“æ— ç­”æ¡ˆï¼Œä¸”æ²¡æœ‰å…¶ä»–å¯ç”¨çŸ¥è¯†åº“",
                error="no_fallback_kbs",
                execution_time=time.time() - start_time
            )

        logger.info(f"[{context.grag_id}] ğŸ”„ æ­¥éª¤2: å¼€å§‹åœ¨ {len(fallback_kbs)} ä¸ªå…¶ä»–çŸ¥è¯†åº“ä¸­è½®è¯¢")

        # å¤ç”¨ç°æœ‰çš„å¤šçŸ¥è¯†åº“æŸ¥è¯¢é€»è¾‘ï¼Œä½†åªä¼ å…¥å›é€€åˆ—è¡¨
        return await self._query_multiple_kbs(context, fallback_kbs, start_time)

    async def _execute_query_logic(self, context: AgentContext) -> dict:
        """
        å†…éƒ¨æ–¹æ³•ï¼šæ ¹æ®ä¸Šä¸‹æ–‡æ‰§è¡Œå•æ¬¡æŸ¥è¯¢ï¼ˆå«å¤æ‚åº¦åˆ†æå’Œæ–¹æ³•é€‰æ‹©ï¼‰
        """
        try:
            # 1. åˆ†æå¤æ‚åº¦
            complexity = await self._analyze_complexity(context.question)

            # 2. é€‰æ‹©æ–¹æ³•
            method = self._select_method(complexity, context)

            # 3. æ‰§è¡ŒæŸ¥è¯¢
            if method == "tog":
                result = self.tog_tool.execute(
                    grag_id=context.grag_id,
                    question=context.question,
                    max_depth=context.metadata.get("max_depth", 5),
                    max_width=context.metadata.get("max_width", 5)
                )
            elif method == "graphrag":
                result = self.graphrag_tool.execute(
                    grag_id=context.grag_id,
                    question=context.question,
                    method=context.metadata.get("graphrag_method", "local")
                )
            else:  # hybrid
                result = await self.hybrid_tool.execute(
                    grag_id=context.grag_id,
                    question=context.question,
                    max_depth=context.metadata.get("max_depth", 5),
                    max_width=context.metadata.get("max_width", 5),
                    method=context.metadata.get("graphrag_method", "local")
                )

            # å°†é€‰æ‹©çš„æ–¹æ³•é™„åŠ åˆ°ç»“æœä¸­ï¼Œæ–¹ä¾¿ä¸Šå±‚åˆ¤æ–­
            result["method"] = method
            return result

        except Exception as e:
            logger.error(f"æŸ¥è¯¢æ‰§è¡Œå¼‚å¸¸: {e}")
            return {"success": False, "error": str(e)}

    async def _query_multiple_kbs(self, context: AgentContext, kb_list: list, start_time: float) -> AgentResult:
        """
        éå†çŸ¥è¯†åº“åˆ—è¡¨è¿›è¡ŒæŸ¥è¯¢ï¼ˆå›é€€æŸ¥è¯¢ä¸“ç”¨ï¼‰
        """
        # åˆ†æä¸€æ¬¡å¤æ‚åº¦å³å¯
        complexity = await self._analyze_complexity(context.question)

        for kb in kb_list:
            kb_grag_id = kb.get("graph_key")
            kb_name = kb.get("name", "æœªçŸ¥")

            logger.info(f"[{kb_grag_id}] ğŸ” å°è¯•å›é€€æŸ¥è¯¢çŸ¥è¯†åº“: {kb_name}")

            # æ›´æ–°ä¸Šä¸‹æ–‡çš„ grag_id
            temp_context = AgentContext(
                grag_id=kb_grag_id,
                question=context.question,
                metadata=context.metadata
            )

            # æ‰§è¡ŒæŸ¥è¯¢
            result = await self._execute_query_logic(temp_context)

            # å¦‚æœæŸ¥è¯¢æˆåŠŸä¸”ç»“æœæœ‰æ•ˆï¼Œè¿”å›
            if result.get("success"):
                answer = result.get("answer") or result.get("final_answer", "")
                if answer and len(answer) > 20:
                    execution_time = time.time() - start_time
                    logger.info(f"[{kb_grag_id}] âœ… å›é€€æŸ¥è¯¢æˆåŠŸï¼Œåœ¨çŸ¥è¯†åº“ '{kb_name}' æ‰¾åˆ°ç­”æ¡ˆ")

                    return AgentResult(
                        success=True,
                        data={
                            "question": context.question,
                            "answer": answer,
                            "method_used": result.get("method"),
                            "complexity": complexity,
                            "grag_id": kb_grag_id,
                        },
                        message=f"æŸ¥è¯¢æˆåŠŸ (çŸ¥è¯†åº“: {kb_name})",
                        execution_time=execution_time,
                        metadata={
                            "method": result.get("method"),
                            "complexity": complexity,
                            "kb_name": kb_name,
                            "is_fallback": True  # æ ‡è®°è¿™æ˜¯å›é€€ç»“æœ
                        }
                    )

        # æ‰€æœ‰å›é€€çŸ¥è¯†åº“éƒ½æŸ¥å®Œäº†ï¼Œæ²¡æ‰¾åˆ°
        execution_time = time.time() - start_time
        kb_names = ", ".join([kb.get("name", "æœªçŸ¥") for kb in kb_list])
        return AgentResult(
            success=False,
            data=None,
            message=f"åœ¨æŒ‡å®šçŸ¥è¯†åº“åŠ {len(kb_list)} ä¸ªå¤‡ç”¨çŸ¥è¯†åº“ä¸­å‡æœªæ‰¾åˆ°ç›¸å…³ç­”æ¡ˆã€‚å·²å°è¯•: {kb_names}",
            error="no_answer_found_in_any_kb",
            execution_time=execution_time
        )

    # ä¿ç•™åŸæœ‰çš„è¾…åŠ©æ–¹æ³•
    async def _analyze_complexity(self, question: str) -> str:
        prompt = f"""åˆ†æé—®é¢˜å¤æ‚åº¦ï¼š{question}\nè¿”å›: simple / moderate / complex"""
        try:
            response = await llm_client.generate(prompt, temperature=0.1)
            if "simple" in response.lower(): return "simple"
            elif "complex" in response.lower(): return "complex"
            return "moderate"
        except:
            return "moderate"

    def _select_method(self, complexity: str, context: AgentContext) -> str:
        query_lower = context.question.lower()
        if "tog" in query_lower or "æ€ç»´å›¾" in query_lower: return "tog"
        if "graphrag" in query_lower: return "graphrag"
        if "æ··åˆ" in query_lower or "hybrid" in query_lower: return "hybrid"

        if complexity == "simple": return "graphrag"
        if complexity == "complex": return "hybrid"
        return "tog"