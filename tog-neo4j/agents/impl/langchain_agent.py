"""
åŸºäº LangChain çš„æ™ºèƒ½æŸ¥è¯¢ Agent
"""
import time
from typing import Dict, Any, List
from langchain_ollama import ChatOllama
from langchain_classic.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage
from agents.base import BaseAgent, AgentContext, AgentResult
from agents.tools.langchain_tools import get_all_tools, GraphRAGTool, ToGTool, HybridQueryTool
from core.config import settings
from utils.logger import logger
from utils.java_backend import get_knowledge_bases


class LangChainQueryAgent(BaseAgent):
    """åŸºäº LangChain çš„æ™ºèƒ½æŸ¥è¯¢ Agent"""

    def __init__(self):
        super().__init__(
            name="LangChainQueryAgent",
            description="ä½¿ç”¨ LangChain æ¡†æ¶çš„æ™ºèƒ½æŸ¥è¯¢ Agentï¼Œæ”¯æŒè‡ªåŠ¨å·¥å…·é€‰æ‹©å’Œæ¨ç†"
        )

        # åˆå§‹åŒ– Ollama LLM
        self.llm = ChatOllama(
            model=settings.llm_model,
            temperature=0.7,
            base_url=settings.llm_api_url,
            timeout=120
        )

        # åˆå§‹åŒ–è§„åˆ’ç”¨çš„ Ollama LLM (ä½æ¸©åº¦)
        self.planning_llm = ChatOllama(
            model=settings.llm_model,
            temperature=0.1,
            base_url=settings.llm_api_url,
            timeout=120
        )

        # è·å–å·¥å…·
        self.tools = get_all_tools()

        # åˆå§‹åŒ–å·¥å…·å®ä¾‹
        self.graphrag_tool = GraphRAGTool()
        self.tog_tool = ToGTool()
        self.hybrid_tool = HybridQueryTool()

        # åˆ›å»º Agent Prompt - å®šä¹‰ä¸LLMäº¤äº’çš„æ¶ˆæ¯ç»“æ„
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", self._get_system_prompt()),  # ç³»ç»Ÿè§’è‰²æ¶ˆæ¯ï¼Œå®šä¹‰Agentçš„è¡Œä¸ºå’Œè§„åˆ™
            MessagesPlaceholder(variable_name="chat_history", optional=True),  # å¯¹è¯å†å²å ä½ç¬¦ï¼Œå¯é€‰ï¼Œç”¨äºä¿æŒå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡
            ("human", "{input}"),                   # äººç±»ç”¨æˆ·è¾“å…¥å ä½ç¬¦ï¼Œæ¥æ”¶ç”¨æˆ·çš„å…·ä½“é—®é¢˜
            MessagesPlaceholder(variable_name="agent_scratchpad"),  # Agentå·¥ä½œåŒºå ä½ç¬¦ï¼Œç”¨äºå­˜å‚¨å·¥å…·è°ƒç”¨å’Œæ€è€ƒè¿‡ç¨‹
        ])

        # åˆ›å»º Agent
        self.agent = create_tool_calling_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=self.prompt
        )

        # åˆ›å»º Agent Executor
        self.agent_executor = AgentExecutor(
            agent=self.agent,
            tools=self.tools,
            verbose=True,
            max_iterations=20,  # å¢åŠ æœ€å¤§è¿­ä»£æ¬¡æ•°ä»¥å¤„ç†æ›´å¤æ‚çš„æŸ¥è¯¢
            max_execution_time=300,  # å¢åŠ æœ€å¤§æ‰§è¡Œæ—¶é—´ä¸º5åˆ†é’Ÿ
            handle_parsing_errors=True,
            return_intermediate_steps=True
        )

        logger.info("âœ… LangChainQueryAgent åˆå§‹åŒ–å®Œæˆ")

    def _get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤º"""
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†å›¾è°±æŸ¥è¯¢åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·é—®é¢˜ï¼Œé€‰æ‹©æœ€åˆé€‚çš„æŸ¥è¯¢å·¥å…·æ¥è·å–ç­”æ¡ˆã€‚
        
        å¯ç”¨å·¥å…·è¯´æ˜:
        1. **graphrag_query**: é€‚ç”¨äºç®€å•çš„äº‹å®æŸ¥è¯¢å’Œä¿¡æ¯æ£€ç´¢ï¼Œæ£€ç´¢é€Ÿåº¦è¾ƒå¿«
        2. **tog_query**: é€‚ç”¨äºéœ€è¦å¤šæ­¥æ¨ç†å’Œé€»è¾‘é“¾çš„å¤æ‚é—®é¢˜ï¼Œæ£€ç´¢é€Ÿåº¦è¾ƒæ…¢
        3. **hybrid_query**: é€‚ç”¨äºéœ€è¦æ·±åº¦æ¨ç†å’Œå¹¿æ³›æ£€ç´¢çš„å¤æ‚é—®é¢˜ï¼Œæ£€ç´¢é€Ÿåº¦æœ€æ…¢
        
        å·¥å…·é€‰æ‹©ç­–ç•¥:
        - ç®€å•é—®é¢˜ (å¦‚"ä»€ä¹ˆæ˜¯X"ã€"Xçš„å®šä¹‰") â†’ ä½¿ç”¨ graphrag_query
        - ä¸­ç­‰å¤æ‚é—®é¢˜ (å¦‚"Xå’ŒYçš„å…³ç³»"ã€"Xå¦‚ä½•å½±å“Y") â†’ ä½¿ç”¨ tog_query
        - å¤æ‚é—®é¢˜ (å¦‚"åˆ†æXçš„å¤šæ–¹é¢å½±å“"ã€"æ¯”è¾ƒXå’ŒYçš„ä¼˜ç¼ºç‚¹") â†’ ä½¿ç”¨ hybrid_query
        
        é‡è¦æç¤º:
        1. é¦–å…ˆåˆ†æé—®é¢˜å¤æ‚åº¦
        2. é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·
        3. å¦‚æœç¬¬ä¸€æ¬¡æŸ¥è¯¢å¤±è´¥æˆ–ç»“æœä¸æ»¡æ„ï¼Œå¯ä»¥å°è¯•å…¶ä»–å·¥å…·
        4. æä¾›æ¸…æ™°ã€ç»“æ„åŒ–çš„ç­”æ¡ˆ
        5. å¦‚æœæŸ¥è¯¢å¤±è´¥ï¼Œè¦æä¾›æœ‰ç”¨çš„é”™è¯¯ä¿¡æ¯
        
        è¯·å§‹ç»ˆä»¥ç”¨æˆ·çš„é—®é¢˜ä¸ºä¸­å¿ƒï¼Œæä¾›å‡†ç¡®ã€æœ‰ç”¨çš„ç­”æ¡ˆã€‚"""

    def can_handle(self, context: AgentContext) -> bool:
        """åˆ¤æ–­æ˜¯å¦èƒ½å¤„ç†è¯¥ä»»åŠ¡"""
        # LangChain Agent å¯ä»¥å¤„ç†æ‰€æœ‰æŸ¥è¯¢ä»»åŠ¡
        return True

    async def execute(self, context: AgentContext) -> AgentResult:
        """æ‰§è¡ŒæŸ¥è¯¢"""
        start_time = time.time()

        try:
            logger.info(f"[{context.grag_id}] ğŸ¤– LangChainQueryAgent å¼€å§‹æ‰§è¡Œ")
            logger.info(f"[{context.grag_id}] ğŸ’¬ é—®é¢˜: {context.question}")

            # å¦‚æœ grag_id ä¸ºç©ºæˆ–ä¸º defaultï¼Œåˆ™è·å–æ‰€æœ‰çŸ¥è¯†åº“å¹¶å¾ªç¯æŸ¥è¯¢
            if not context.grag_id or context.grag_id == "default":
                logger.info("ğŸ“š grag_id ä¸ºç©ºï¼Œå¼€å§‹è·å–çŸ¥è¯†åº“åˆ—è¡¨å¹¶å¾ªç¯æŸ¥è¯¢")

                # è·å–çŸ¥è¯†åº“åˆ—è¡¨
                knowledge_bases = await get_knowledge_bases()

                if not knowledge_bases:
                    logger.warning("âŒ æœªæ‰¾åˆ°ä»»ä½•çŸ¥è¯†åº“")
                    return AgentResult(
                        success=False,
                        data=None,
                        message="æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„çŸ¥è¯†åº“",
                        error="no_knowledge_bases_found",
                        execution_time=time.time() - start_time
                    )

                logger.info(f"âœ… è·å–åˆ° {len(knowledge_bases)} ä¸ªçŸ¥è¯†åº“: {[kb['name'] for kb in knowledge_bases]}")

                # éå†çŸ¥è¯†åº“è¿›è¡ŒæŸ¥è¯¢
                for kb in knowledge_bases:
                    kb_grag_id = kb.get("graph_key") or kb.get("grag_id")
                    kb_name = kb.get("name", "æœªçŸ¥çŸ¥è¯†åº“")

                    # æ£€æŸ¥æ˜¯å¦è·å–åˆ°äº†æœ‰æ•ˆçš„ grag_id
                    if not kb_grag_id:
                        logger.warning(f"âš ï¸ çŸ¥è¯†åº“ '{kb_name}' ç¼ºå°‘ graph_key æˆ– grag_idï¼Œè·³è¿‡")
                        continue

                    logger.info(f"[{kb_grag_id}] ğŸ” å°è¯•æŸ¥è¯¢çŸ¥è¯†åº“: {kb_name}")

                    # åˆ›å»ºæ–°çš„ä¸Šä¸‹æ–‡ï¼Œä½¿ç”¨å½“å‰çŸ¥è¯†åº“ID
                    kb_context = AgentContext(
                        grag_id=kb_grag_id,
                        question=context.question,
                        conversation_history=context.conversation_history,
                        metadata=context.metadata
                    )

                    # æ‰§è¡ŒæŸ¥è¯¢ï¼ˆä¸åŒ…å«éªŒè¯é€»è¾‘ï¼‰
                    result = await self._execute_single_query(kb_context, kb_name, validate_answer=False)

                    # åœ¨å¤–å±‚å¾ªç¯ä¸­è¿›è¡Œå¤§æ¨¡å‹éªŒè¯ï¼Œé¿å…æ¯ä¸ªçŸ¥è¯†åº“éƒ½éªŒè¯
                    if result.data and result.data.get("answer"):
                        answer = result.data["answer"]
                        is_valid = await self._validate_answer(context.question, answer)

                        if is_valid:
                            logger.info(f"[{kb_grag_id}] âœ… åœ¨çŸ¥è¯†åº“ '{kb_name}' ä¸­æ‰¾åˆ°æœ‰æ•ˆç­”æ¡ˆ")

                            execution_time = time.time() - start_time
                            result.execution_time = execution_time
                            result.success = True
                            result.message = f"åœ¨çŸ¥è¯†åº“ '{kb_name}' ä¸­æŸ¥è¯¢æˆåŠŸ"
                            return result
                        else:
                            logger.info(f"[{kb_grag_id}] âš ï¸ çŸ¥è¯†åº“ '{kb_name}' ç­”æ¡ˆéªŒè¯å¤±è´¥ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ª")
                            continue
                    else:
                        logger.info(f"[{kb_grag_id}] âš ï¸ çŸ¥è¯†åº“ '{kb_name}' æŸ¥è¯¢å¤±è´¥ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ª")
                        continue

                # æ‰€æœ‰çŸ¥è¯†åº“éƒ½æŸ¥è¯¢å¤±è´¥
                logger.error("âŒ æ‰€æœ‰çŸ¥è¯†åº“æŸ¥è¯¢éƒ½å¤±è´¥")
                execution_time = time.time() - start_time
                return AgentResult(
                    success=False,
                    data=None,
                    message="åœ¨æ‰€æœ‰çŸ¥è¯†åº“ä¸­éƒ½æœªèƒ½æ‰¾åˆ°æ»¡æ„ç­”æ¡ˆ",
                    error="all_knowledge_bases_failed",
                    execution_time=execution_time
                )
            else:
                # åŸæœ‰é€»è¾‘ï¼šæŒ‡å®šçŸ¥è¯†åº“æŸ¥è¯¢
                logger.info(f"[{context.grag_id}] ğŸ¯ æ‰§è¡ŒæŒ‡å®šçŸ¥è¯†åº“æŸ¥è¯¢")

                # æ‰§è¡Œå®Œæ•´çš„æŸ¥è¯¢æµç¨‹
                result = await self._execute_single_query(context, "æŒ‡å®šçŸ¥è¯†åº“")
                execution_time = time.time() - start_time
                result.execution_time = execution_time
                return result

        except Exception as e:
            logger.error(f"LangChainQueryAgent æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            return AgentResult(
                success=False,
                data=None,
                message="æŸ¥è¯¢å¤±è´¥",
                error=str(e),
                execution_time=time.time() - start_time
            )

    def _prepare_input(self, context: AgentContext) -> Dict[str, Any]:
        """å‡†å¤‡ Agent è¾“å…¥"""
        # è½¬æ¢å¯¹è¯å†å²ä¸º LangChain æ ¼å¼
        chat_history = []
        for msg in context.conversation_history:
            if msg["role"] == "user":
                chat_history.append(HumanMessage(content=msg["content"]))
            elif msg["role"] == "assistant":
                chat_history.append(AIMessage(content=msg["content"]))

        # æ„å»ºè¾“å…¥
        input_text = f"""
çŸ¥è¯†åº“ID: {context.grag_id}
ç”¨æˆ·é—®é¢˜: {context.question}

è¯·é€‰æ‹©åˆé€‚çš„å·¥å…·æŸ¥è¯¢å¹¶è¿”å›ç­”æ¡ˆã€‚
"""

        return {
            "input": input_text,
            "chat_history": chat_history
        }

    def _extract_tools_used(self, result: Dict[str, Any]) -> List[str]:
        """ä»ç»“æœä¸­æå–ä½¿ç”¨çš„å·¥å…·"""
        intermediate_steps = result.get("intermediate_steps", [])
        tools_used = []
        for step in intermediate_steps:
            if len(step) > 0:
                action = step[0]
                tools_used.append(action.tool)
        return tools_used

    def _parse_result(
        self,
        result: Dict[str, Any],
        context: AgentContext,
        execution_time: float
    ) -> AgentResult:
        """è§£æ Agent æ‰§è¡Œç»“æœ"""
        output = result.get("output", "")
        intermediate_steps = result.get("intermediate_steps", [])

        # æå–ä½¿ç”¨çš„å·¥å…·
        tools_used = self._extract_tools_used(result)

        logger.info(f"âœ… æŸ¥è¯¢å®Œæˆï¼Œä½¿ç”¨çš„å·¥å…·: {', '.join(tools_used)}")
        logger.info(f"â±ï¸ æ€»è€—æ—¶: {execution_time:.2f}ç§’")

        return AgentResult(
            success=True,
            data={
                "question": context.question,
                "answer": output,
                "grag_id": context.grag_id,
                "tools_used": tools_used
            },
            message="æŸ¥è¯¢æˆåŠŸ",
            execution_time=execution_time,
            metadata={
                "tools_used": tools_used,
                "intermediate_steps": len(intermediate_steps)
            }
        )

    async def _execute_single_query(
        self,
        context: AgentContext,
        kb_name: str = "æœªçŸ¥çŸ¥è¯†åº“",
        validate_answer: bool = True
    ) -> AgentResult:
        """æ‰§è¡Œå•ä¸ªçŸ¥è¯†åº“çš„å®Œæ•´æŸ¥è¯¢æµç¨‹

        Args:
            context: æŸ¥è¯¢ä¸Šä¸‹æ–‡
            kb_name: çŸ¥è¯†åº“åç§°
            validate_answer: æ˜¯å¦éªŒè¯ç­”æ¡ˆè´¨é‡ï¼ˆé»˜è®¤Trueï¼Œè®¾ä¸ºFalseæ—¶è·³è¿‡å¤§æ¨¡å‹éªŒè¯ï¼‰

        Returns:
            AgentResult: æŸ¥è¯¢ç»“æœ
        """
        start_time = time.time()

        # åˆ†æé—®é¢˜å¤æ‚åº¦
        complexity = await self._analyze_complexity(context.question)

        # é€‰æ‹©æŸ¥è¯¢æ–¹æ³•
        method = await self._select_method(complexity, context.question)

        # æ ¹æ®é€‰æ‹©çš„æ–¹æ³•æ‰§è¡ŒæŸ¥è¯¢
        result = await self._execute_query_with_method(context.grag_id, context.question, method)

        # è®°å½•ä½¿ç”¨çš„å·¥å…·
        tools_used = [method]

        execution_time = time.time() - start_time

        # æ ¹æ® validate_answer å‚æ•°å†³å®šæ˜¯å¦éªŒè¯ç­”æ¡ˆ
        is_valid = True
        if validate_answer:
            # ä½¿ç”¨å¤§æ¨¡å‹éªŒè¯ç­”æ¡ˆè´¨é‡
            is_valid = await self._validate_answer(context.question, result)

        return AgentResult(
            success=is_valid,
            data={
                "question": context.question,
                "answer": result,
                "grag_id": context.grag_id,
                "kb_name": kb_name,
                "tools_used": tools_used
            },
            message="æŸ¥è¯¢æˆåŠŸ" if is_valid else "æŸ¥è¯¢å¤±è´¥",
            execution_time=execution_time,
            metadata={
                "complexity": complexity,
                "method": method,
                "tools_used": tools_used,
                "kb_used": kb_name,
                "kb_grag_id": context.grag_id
            }
        )

    async def _analyze_complexity(self, question: str) -> str:
        """åˆ†æé—®é¢˜å¤æ‚åº¦"""
        from langchain_core.prompts import ChatPromptTemplate

        logger.info("ğŸ“Š åˆ†æé—®é¢˜å¤æ‚åº¦...")

        prompt = ChatPromptTemplate.from_template(
            "åˆ†æä»¥ä¸‹é—®é¢˜çš„å¤æ‚åº¦ï¼Œè¿”å›: simple, moderate, æˆ– complex\né—®é¢˜: {question}"
        )

        chain = prompt | self.planning_llm
        response = await chain.ainvoke({"question": question})

        complexity = "moderate"
        content = response.content.lower()
        if "simple" in content:
            complexity = "simple"
        elif "complex" in content:
            complexity = "complex"

        logger.info(f"âœ… å¤æ‚åº¦: {complexity}")

        return complexity

    async def _select_method(self, complexity: str, question: str) -> str:
        """é€‰æ‹©æŸ¥è¯¢æ–¹æ³•"""
        logger.info("ğŸ¯ é€‰æ‹©æŸ¥è¯¢æ–¹æ³•...")

        question_lower = question.lower()

        # æ£€æŸ¥æ˜¾å¼æŒ‡å®š
        if "tog" in question_lower or "æ€ç»´å›¾" in question_lower:
            method = "tog"
        elif "graphrag" in question_lower:
            method = "graphrag"
        elif "æ··åˆ" in question_lower or "hybrid" in question_lower:
            method = "hybrid"
        else:
            # æ ¹æ®å¤æ‚åº¦é€‰æ‹©
            if complexity == "simple":
                method = "graphrag"
            elif complexity == "complex":
                method = "hybrid"
            else:
                method = "tog"

        logger.info(f"âœ… é€‰æ‹©æ–¹æ³•: {method}")

        return method

    async def _execute_query_with_method(self, grag_id: str, question: str, method: str) -> str:
        """æ ¹æ®é€‰æ‹©çš„æ–¹æ³•æ‰§è¡ŒæŸ¥è¯¢"""
        logger.info(f"ğŸ” ä½¿ç”¨æ–¹æ³• {method} æŸ¥è¯¢çŸ¥è¯†åº“: {grag_id}")

        try:
            if method == "graphrag":
                result = self.graphrag_tool._run(grag_id, question)
            elif method == "tog":
                result = self.tog_tool._run(grag_id, question)
            else:  # hybrid
                result = await self.hybrid_tool._arun(grag_id, question)

            logger.info(f"âœ… {method} æŸ¥è¯¢å®Œæˆ")
            return result

        except Exception as e:
            error_msg = f"æŸ¥è¯¢å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return error_msg

    async def _validate_answer(self, question: str, answer: str) -> bool:
        """ä½¿ç”¨å¤§æ¨¡å‹éªŒè¯ç­”æ¡ˆè´¨é‡

        Args:
            question: åŸå§‹é—®é¢˜
            answer: å¾…éªŒè¯çš„ç­”æ¡ˆ

        Returns:
            bool: ç­”æ¡ˆæ˜¯å¦æœ‰æ•ˆ
        """
        logger.info("ğŸ¤– ä½¿ç”¨å¤§æ¨¡å‹éªŒè¯ç­”æ¡ˆè´¨é‡...")

        # æ£€æŸ¥ç­”æ¡ˆåŸºæœ¬å±æ€§
        if not answer or not isinstance(answer, str):
            logger.info("âŒ ç­”æ¡ˆä¸ºç©ºæˆ–éå­—ç¬¦ä¸²")
            return False

        # æ¸…ç†ç­”æ¡ˆæ–‡æœ¬
        cleaned_answer = answer.strip()

        # # æ£€æŸ¥æ˜¯å¦æ˜æ˜¾æ˜¯é”™è¯¯ä¿¡æ¯
        # error_indicators = [
        #     "æœªæ‰¾åˆ°", "not found", "no result",
        #     "error", "exception", "failed", "not available",
        #     "æ— æ³•å›ç­”", "æ²¡æœ‰æ‰¾åˆ°", "ä¸å­˜åœ¨", "æš‚æ— ", "æ²¡æœ‰ç›¸å…³ä¿¡æ¯", "æ²¡æœ‰å¯ç”¨ç»“æœ",
        #     "æ²¡æœ‰æ£€ç´¢åˆ°ç›¸å…³å†…å®¹", "æ£€ç´¢å¤±è´¥", "æŸ¥è¯¢å¤±è´¥",
        #     "Agent stopped due to max iterations", "max iterations"
        # ]
        #
        # for indicator in error_indicators:
        #     if indicator in cleaned_answer:
        #         logger.info(f"âŒ ç­”æ¡ˆåŒ…å«é”™è¯¯æŒ‡ç¤ºç¬¦: {indicator}")
        #         return False

        # å¦‚æœç­”æ¡ˆé•¿åº¦å¤ªçŸ­ï¼Œç›´æ¥è§†ä¸ºæ— æ•ˆ
        if len(cleaned_answer) < 20:
            logger.info(f"âŒ ç­”æ¡ˆé•¿åº¦ä¸è¶³ ({len(cleaned_answer)} å­—ç¬¦)")
            return False

        # ä½¿ç”¨å¤§æ¨¡å‹è¯„ä¼°ç­”æ¡ˆè´¨é‡
        try:
            from langchain_core.prompts import ChatPromptTemplate

            validation_prompt = ChatPromptTemplate.from_template(
                """è¯·è¯„ä¼°ä»¥ä¸‹ç­”æ¡ˆæ˜¯å¦æœ‰æ•ˆå›ç­”äº†ç”¨æˆ·çš„é—®é¢˜ã€‚
                
ç”¨æˆ·é—®é¢˜: {question}

AIå›ç­”: {answer}

è¯·ä»…å›ç­” "VALID" å¦‚æœå›ç­”æœ‰æ•ˆï¼Œå¦åˆ™å›ç­” "INVALID"ã€‚åˆ¤æ–­æ ‡å‡†ï¼š
1. å›ç­”æ˜¯å¦ç›´æ¥é’ˆå¯¹é—®é¢˜
2. å›ç­”æ˜¯å¦æä¾›äº†æœ‰ç”¨ä¿¡æ¯
3. å›ç­”æ˜¯å¦å®Œæ•´æˆ–è‡³å°‘æä¾›äº†éƒ¨åˆ†æœ‰ç”¨ä¿¡æ¯
4. å›ç­”æ˜¯å¦ä¸æ˜¯æ‹’ç»å›ç­”æˆ–é”™è¯¯ä¿¡æ¯

è¯„ä¼°:"""
            )

            chain = validation_prompt | self.planning_llm
            response = await chain.ainvoke({"question": question, "answer": answer})

            # è§£æå¤§æ¨¡å‹çš„è¯„ä¼°ç»“æœ
            content = response.content.strip().upper()
            # ä¿®å¤é€»è¾‘ï¼šå¿…é¡»åŒ…å« VALID ä¸”ä¸åŒ…å« INVALIDï¼Œé˜²æ­¢ "INVALID" è¢«é”™è¯¯åˆ¤å®šä¸º True
            is_valid = "VALID" in content and "INVALID" not in content

            logger.info(f"âœ… å¤§æ¨¡å‹è¯„ä¼°ç»“æœ: {'æœ‰æ•ˆ' if is_valid else 'æ— æ•ˆ'}")
            return is_valid

        except Exception as e:
            logger.error(f"å¤§æ¨¡å‹éªŒè¯ç­”æ¡ˆæ—¶å‡ºé”™: {e}")
            # å¦‚æœå¤§æ¨¡å‹éªŒè¯å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨éªŒè¯æ–¹æ³•
            return self._fallback_validate_answer(answer)

    def _fallback_validate_answer(self, answer: str) -> bool:
        """å¤‡ç”¨ç­”æ¡ˆéªŒè¯æ–¹æ³•"""
        logger.info("ğŸ”„ ä½¿ç”¨å¤‡ç”¨éªŒè¯æ–¹æ³•")

        # æ£€æŸ¥ç­”æ¡ˆåŸºæœ¬å±æ€§
        if not answer or not isinstance(answer, str):
            logger.info("âŒ ç­”æ¡ˆä¸ºç©ºæˆ–éå­—ç¬¦ä¸²")
            return False

        # æ¸…ç†ç­”æ¡ˆæ–‡æœ¬
        cleaned_answer = answer.strip()

        # æ£€æŸ¥é•¿åº¦
        if len(cleaned_answer) < 20:
            logger.info(f"âŒ ç­”æ¡ˆé•¿åº¦ä¸è¶³ ({len(cleaned_answer)} å­—ç¬¦)")
            return False

        # # æ£€æŸ¥æ˜¯å¦åŒ…å«æ˜æ˜¾çš„é”™è¯¯ä¿¡æ¯
        # error_indicators = [
        #     "å¤±è´¥", "é”™è¯¯", "æœªæ‰¾åˆ°", "not found", "no result",
        #     "error", "exception", "failed", "not available", "æš‚æ—¶æ— æ³•", "æŠ±æ­‰",
        #     "æ— æ³•å›ç­”", "æ²¡æœ‰æ‰¾åˆ°", "ä¸å­˜åœ¨", "æš‚æ— ", "æ²¡æœ‰ç›¸å…³ä¿¡æ¯", "æ²¡æœ‰å¯ç”¨ç»“æœ",
        #     "æ²¡æœ‰æ£€ç´¢åˆ°ç›¸å…³å†…å®¹", "æ£€ç´¢å¤±è´¥", "æŸ¥è¯¢å¤±è´¥",
        #     "Agent stopped due to max iterations", "max iterations"
        # ]
        #
        # for indicator in error_indicators:
        #     if indicator in cleaned_answer:
        #         logger.info(f"âŒ ç­”æ¡ˆåŒ…å«é”™è¯¯æŒ‡ç¤ºç¬¦: {indicator}")
        #         return False

        logger.info("âœ… é€šè¿‡å¤‡ç”¨éªŒè¯")
        return True
