"""
åŸºäº LangChain çš„æ™ºèƒ½æŸ¥è¯¢ Agent
"""
import time
from typing import Dict, Any, List
from langchain_ollama import ChatOllama
from langchain_classic.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage
from agents.base import BaseAgent, AgentContext, AgentResult
from agents.tools.langchain_tools import get_all_tools
from core.config import settings
from utils.logger import logger
from utils.java_backend import get_knowledge_bases


class LangChainQueryAgent(BaseAgent):
    """åŸºäº LangChain çš„æ™ºèƒ½æŸ¥è¯¢ Agent"""

    def __init__(self):
        super().__init__(
            name="LangChainQueryAgent",
            description="ä½¿ç”¨ LangChain æ¡†æ¶çš„æ™ºèƒ½æŸ¥è¯¢ Agentï¼Œæ”¯æŒè‡ªåŠ¨å·¥å…·é€‰æ‹©å’Œæ¨ç†"
        )

        # åˆå§‹åŒ– Ollama LLM
        self.llm = ChatOllama(
            model=settings.llm_model,
            temperature=0.7,
            base_url=settings.llm_api_url,
            timeout=120
        )

        # è·å–å·¥å…·
        self.tools = get_all_tools()

        # åˆ›å»º Agent Prompt
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", self._get_system_prompt()),
            MessagesPlaceholder(variable_name="chat_history", optional=True),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])

        # åˆ›å»º Agent
        self.agent = create_tool_calling_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=self.prompt
        )

        # åˆ›å»º Agent Executor
        self.agent_executor = AgentExecutor(
            agent=self.agent,
            tools=self.tools,
            verbose=True,
            max_iterations=5,
            max_execution_time=120,
            handle_parsing_errors=True,
            return_intermediate_steps=True
        )

        logger.info("âœ… LangChainQueryAgent åˆå§‹åŒ–å®Œæˆ")

    def _get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤º"""
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†å›¾è°±æŸ¥è¯¢åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·é—®é¢˜ï¼Œé€‰æ‹©æœ€åˆé€‚çš„æŸ¥è¯¢å·¥å…·æ¥è·å–ç­”æ¡ˆã€‚

å¯ç”¨å·¥å…·è¯´æ˜:
1. **graphrag_query**: é€‚ç”¨äºç®€å•çš„äº‹å®æŸ¥è¯¢å’Œä¿¡æ¯æ£€ç´¢
2. **tog_query**: é€‚ç”¨äºéœ€è¦å¤šæ­¥æ¨ç†å’Œé€»è¾‘é“¾çš„å¤æ‚é—®é¢˜
3. **hybrid_query**: é€‚ç”¨äºéœ€è¦æ·±åº¦æ¨ç†å’Œå¹¿æ³›æ£€ç´¢çš„å¤æ‚é—®é¢˜

å·¥å…·é€‰æ‹©ç­–ç•¥:
- ç®€å•é—®é¢˜ (å¦‚"ä»€ä¹ˆæ˜¯X"ã€"Xçš„å®šä¹‰") â†’ ä½¿ç”¨ graphrag_query
- ä¸­ç­‰å¤æ‚é—®é¢˜ (å¦‚"Xå’ŒYçš„å…³ç³»"ã€"Xå¦‚ä½•å½±å“Y") â†’ ä½¿ç”¨ tog_query
- å¤æ‚é—®é¢˜ (å¦‚"åˆ†æXçš„å¤šæ–¹é¢å½±å“"ã€"æ¯”è¾ƒXå’ŒYçš„ä¼˜ç¼ºç‚¹") â†’ ä½¿ç”¨ hybrid_query

é‡è¦æç¤º:
1. é¦–å…ˆåˆ†æé—®é¢˜å¤æ‚åº¦
2. é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·
3. å¦‚æœç¬¬ä¸€æ¬¡æŸ¥è¯¢å¤±è´¥æˆ–ç»“æœä¸æ»¡æ„ï¼Œå¯ä»¥å°è¯•å…¶ä»–å·¥å…·
4. æä¾›æ¸…æ™°ã€ç»“æ„åŒ–çš„ç­”æ¡ˆ
5. å¦‚æœæŸ¥è¯¢å¤±è´¥ï¼Œè¦æä¾›æœ‰ç”¨çš„é”™è¯¯ä¿¡æ¯

è¯·å§‹ç»ˆä»¥ç”¨æˆ·çš„é—®é¢˜ä¸ºä¸­å¿ƒï¼Œæä¾›å‡†ç¡®ã€æœ‰ç”¨çš„ç­”æ¡ˆã€‚"""

    def can_handle(self, context: AgentContext) -> bool:
        """åˆ¤æ–­æ˜¯å¦èƒ½å¤„ç†è¯¥ä»»åŠ¡"""
        # LangChain Agent å¯ä»¥å¤„ç†æ‰€æœ‰æŸ¥è¯¢ä»»åŠ¡
        return True

    async def execute(self, context: AgentContext) -> AgentResult:
        """æ‰§è¡ŒæŸ¥è¯¢"""
        start_time = time.time()

        try:
            logger.info(f"[{context.grag_id}] ğŸ¤– LangChainQueryAgent å¼€å§‹æ‰§è¡Œ")
            logger.info(f"[{context.grag_id}] ğŸ’¬ é—®é¢˜: {context.question}")

            # å¦‚æœ grag_id ä¸ºç©ºæˆ–ä¸º defaultï¼Œåˆ™è·å–æ‰€æœ‰çŸ¥è¯†åº“å¹¶å¾ªç¯æŸ¥è¯¢
            if not context.grag_id or context.grag_id == "default":
                logger.info("ğŸ“š grag_id ä¸ºç©ºï¼Œå¼€å§‹è·å–çŸ¥è¯†åº“åˆ—è¡¨å¹¶å¾ªç¯æŸ¥è¯¢")
                
                # è·å–çŸ¥è¯†åº“åˆ—è¡¨
                knowledge_bases = await get_knowledge_bases()
                
                if not knowledge_bases:
                    logger.warning("âŒ æœªæ‰¾åˆ°ä»»ä½•çŸ¥è¯†åº“")
                    return AgentResult(
                        success=False,
                        data=None,
                        message="æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„çŸ¥è¯†åº“",
                        error="no_knowledge_bases_found",
                        execution_time=time.time() - start_time
                    )
                
                logger.info(f"âœ… è·å–åˆ° {len(knowledge_bases)} ä¸ªçŸ¥è¯†åº“: {[kb['name'] for kb in knowledge_bases]}")
                
                # éå†çŸ¥è¯†åº“è¿›è¡ŒæŸ¥è¯¢
                for kb in knowledge_bases:
                    kb_grag_id = kb.get("graph_key") or kb.get("grag_id")
                    kb_name = kb.get("name", "æœªçŸ¥çŸ¥è¯†åº“")
                    
                    logger.info(f"[{kb_grag_id}] ğŸ” å°è¯•æŸ¥è¯¢çŸ¥è¯†åº“: {kb_name}")
                    
                    # åˆ›å»ºæ–°çš„ä¸Šä¸‹æ–‡ï¼Œä½¿ç”¨å½“å‰çŸ¥è¯†åº“ID
                    kb_context = AgentContext(
                        grag_id=kb_grag_id,
                        question=context.question,
                        conversation_history=context.conversation_history,
                        metadata=context.metadata
                    )
                    
                    # å‡†å¤‡è¾“å…¥
                    agent_input = self._prepare_input(kb_context)

                    try:
                        # æ‰§è¡Œ Agent
                        result = await self.agent_executor.ainvoke(agent_input)
                        
                        # æ£€æŸ¥ç»“æœæ˜¯å¦æœ‰æ•ˆï¼ˆä¾‹å¦‚ï¼Œç­”æ¡ˆé•¿åº¦å¤§äºä¸€å®šé˜ˆå€¼ï¼‰
                        output = result.get("output", "")
                        if output and len(output.strip()) > 20:  # ç®€å•çš„æœ‰æ•ˆæ€§æ£€æŸ¥
                            logger.info(f"[{kb_grag_id}] âœ… åœ¨çŸ¥è¯†åº“ '{kb_name}' ä¸­æ‰¾åˆ°æœ‰æ•ˆç­”æ¡ˆ")
                            
                            execution_time = time.time() - start_time
                            return AgentResult(
                                success=True,
                                data={
                                    "question": context.question,
                                    "answer": output,
                                    "grag_id": kb_grag_id,
                                    "kb_name": kb_name,
                                    "tools_used": self._extract_tools_used(result)
                                },
                                message=f"åœ¨çŸ¥è¯†åº“ '{kb_name}' ä¸­æŸ¥è¯¢æˆåŠŸ",
                                execution_time=execution_time,
                                metadata={
                                    "tools_used": self._extract_tools_used(result),
                                    "kb_used": kb_name,
                                    "kb_grag_id": kb_grag_id
                                }
                            )
                        else:
                            logger.info(f"[{kb_grag_id}] âš ï¸ çŸ¥è¯†åº“ '{kb_name}' æŸ¥è¯¢ç»“æœæ— æ•ˆï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ª")
                            continue
                    except Exception as kb_error:
                        logger.error(f"[{kb_grag_id}] âŒ æŸ¥è¯¢çŸ¥è¯†åº“ '{kb_name}' æ—¶å‡ºé”™: {kb_error}")
                        continue
                
                # æ‰€æœ‰çŸ¥è¯†åº“éƒ½æŸ¥è¯¢å¤±è´¥
                logger.error("âŒ æ‰€æœ‰çŸ¥è¯†åº“æŸ¥è¯¢éƒ½å¤±è´¥")
                execution_time = time.time() - start_time
                return AgentResult(
                    success=False,
                    data=None,
                    message="åœ¨æ‰€æœ‰çŸ¥è¯†åº“ä¸­éƒ½æœªèƒ½æ‰¾åˆ°æ»¡æ„ç­”æ¡ˆ",
                    error="all_knowledge_bases_failed",
                    execution_time=execution_time
                )
            else:
                # åŸæœ‰é€»è¾‘ï¼šæŒ‡å®šçŸ¥è¯†åº“æŸ¥è¯¢
                logger.info(f"[{context.grag_id}] ğŸ¯ æ‰§è¡ŒæŒ‡å®šçŸ¥è¯†åº“æŸ¥è¯¢")
                
                # å‡†å¤‡è¾“å…¥
                agent_input = self._prepare_input(context)

                # æ‰§è¡Œ Agent
                result = await self.agent_executor.ainvoke(agent_input)

                # è§£æç»“æœ
                return self._parse_result(result, context, time.time() - start_time)

        except Exception as e:
            logger.error(f"LangChainQueryAgent æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            return AgentResult(
                success=False,
                data=None,
                message="æŸ¥è¯¢å¤±è´¥",
                error=str(e),
                execution_time=time.time() - start_time
            )

    def _prepare_input(self, context: AgentContext) -> Dict[str, Any]:
        """å‡†å¤‡ Agent è¾“å…¥"""
        # è½¬æ¢å¯¹è¯å†å²ä¸º LangChain æ ¼å¼
        chat_history = []
        for msg in context.conversation_history:
            if msg["role"] == "user":
                chat_history.append(HumanMessage(content=msg["content"]))
            elif msg["role"] == "assistant":
                chat_history.append(AIMessage(content=msg["content"]))

        # æ„å»ºè¾“å…¥
        input_text = f"""
çŸ¥è¯†åº“ID: {context.grag_id}
ç”¨æˆ·é—®é¢˜: {context.question}

è¯·é€‰æ‹©åˆé€‚çš„å·¥å…·æŸ¥è¯¢å¹¶è¿”å›ç­”æ¡ˆã€‚
"""

        return {
            "input": input_text,
            "chat_history": chat_history
        }

    def _extract_tools_used(self, result: Dict[str, Any]) -> List[str]:
        """ä»ç»“æœä¸­æå–ä½¿ç”¨çš„å·¥å…·"""
        intermediate_steps = result.get("intermediate_steps", [])
        tools_used = []
        for step in intermediate_steps:
            if len(step) > 0:
                action = step[0]
                tools_used.append(action.tool)
        return tools_used

    def _parse_result(
        self,
        result: Dict[str, Any],
        context: AgentContext,
        execution_time: float
    ) -> AgentResult:
        """è§£æ Agent æ‰§è¡Œç»“æœ"""
        output = result.get("output", "")
        intermediate_steps = result.get("intermediate_steps", [])

        # æå–ä½¿ç”¨çš„å·¥å…·
        tools_used = self._extract_tools_used(result)

        logger.info(f"âœ… æŸ¥è¯¢å®Œæˆï¼Œä½¿ç”¨çš„å·¥å…·: {', '.join(tools_used)}")
        logger.info(f"â±ï¸ æ€»è€—æ—¶: {execution_time:.2f}ç§’")

        return AgentResult(
            success=True,
            data={
                "question": context.question,
                "answer": output,
                "grag_id": context.grag_id,
                "tools_used": tools_used
            },
            message="æŸ¥è¯¢æˆåŠŸ",
            execution_time=execution_time,
            metadata={
                "tools_used": tools_used,
                "intermediate_steps": len(intermediate_steps)
            }
        )